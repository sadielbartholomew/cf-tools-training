{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CF-netCDF with cfdm, cf-python and cf-plot: a demo in under an hour\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A ~45 minute illustration of the basic functionality of three inter-related Python libraries\\* underpinned by [the CF data model](https://gmd.copernicus.org/articles/10/4619/2017/) for working with CF-netCDF.\n",
    "\n",
    "\\* these data tools are developed & maintained by the [CMS team](https://www.ncas.ac.uk/en/cms) of the National Centre for Atmospheric Science (NCAS)\n",
    "\n",
    "A recap of the data tools and their respective scopes are:\n",
    "\n",
    "* #### [cfdm](https://ncas-cms.github.io/cfdm/) (`cfdm` module): reference implementation of the CF data model with mostly only the functionality required to read and write datasets, and to create, modify and inspect field constructs in memory;\n",
    "* #### [cf-python](https://ncas-cms.github.io/cf-python/) (`cf`): CF-compliant geoscientific data analysis library which builds upon `cfdm` to provide much higher-level functionality, for example statistical operations, collapsing, subspacing, and regridding;\n",
    "* #### [cf-plot](http://ajheaps.github.io/cf-plot/) (`cfplot`): set of Python functions for making common visualisations such as contour, vector and line plots that are used often by geoscientists.\n",
    "\n",
    "*Note*: this summary focuses on use of these tools *with netCDF (`.nc`) datasets only*, however cfdm and cf-python can recognise and map to field constructs other formats, namely CDL (`.cdl`) of netCDF and (for cf-python only) PP (`.pp`) and UM fields files (`.ff`), and cf-plot also accepts pure NumPy arrays as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives:\n",
    "\n",
    "### ~10 minutes for each of four segments demonstrating some (but by no means all!) of the capabilities of the tools:\n",
    "\n",
    "1. **From netCDF to field constructs and back**: read in netCDF files, create a new field construct by modification of data and metadata and then write out the new field to a new netCDF file.\n",
    "2. **Basic data analysis, with plotting of results**: Plot the data before and after applying statistical collapses.\n",
    "3. **Regridding domains, with plotting of results**:  plot the data before and after regridding across spherical and cartesian coordinate systems.\n",
    "4. **Manipulating hierarchical groups**: create & inspect group structure for a netCDF-4 file, then flatten it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's setup the Notebook environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for nice outputs in this Jupyter Notebook (not required in interactive Python or a script)\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this walk-through we will be working on some sample datasets, contained in `ncas_data`. Let's check what we have to work with, with a shell command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'ncas_data/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Note that in IPython ! preceeeds a shell command\n",
    "!ls -1 ncas_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are plenty of netCDF files to work with. Note there is a mixture of \"classic\" netCDF-3 and netCDF-4, as some futher shell commands illustrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncdump: ncas_data/data1.nc: No such file or directory\n",
      "ncdump: ncas_data/data2.nc: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Note that in IPython ! preceeeds a shell command\n",
    "!ncdump -k ncas_data/data1.nc\n",
    "!ncdump -k ncas_data/data2.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start, naturally, by importing the CF data tools modules. Note the standard alias used for `cfplot` e.g. within the module documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfdm\n",
    "import cf\n",
    "import cfplot as cfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. We are now all ready to go using these modules on the netCDF datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 1. From netCDF to field constructs and back\n",
    "\n",
    "### Read in netCDF files, create a new field construct by modification of data and metadata and then write out the new field to a new netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Report._add_message() got an unexpected keyword argument 'variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read a data file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m field_list \u001b[38;5;241m=\u001b[39m \u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../ncas_data/ua.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git-repos/cfdm/cfdm/decorators.py:171\u001b[0m, in \u001b[0;36m_manage_log_level_via_verbosity.<locals>.verbose_override_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# After method completes, re-set any changes to log level or\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# enabling\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod_with_verbose_kwarg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/git-repos/cf-python/cf/read_write/read.py:538\u001b[0m, in \u001b[0;36mread.__new__\u001b[0;34m(cls, datasets, external, verbose, warnings, aggregate, nfields, squeeze, unsqueeze, dataset_type, cdl_string, select, extra, recursive, followlinks, um, chunk, field, height_at_top_of_model, select_options, follow_symlinks, mask, unpack, warn_valid, dask_chunks, store_dataset_chunks, store_dataset_shards, domain, cfa, cfa_write, to_memory, netcdf_backend, storage_options, cache, chunks, ignore_read_error, fmt, file_type, group_dimension_search)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     _DEPRECATION_ERROR_FUNCTION_KWARGS(\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcf.read\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    532\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_type},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m         removed_at\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    536\u001b[0m     )  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git-repos/cfdm/cfdm/decorators.py:171\u001b[0m, in \u001b[0;36m_manage_log_level_via_verbosity.<locals>.verbose_override_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# After method completes, re-set any changes to log level or\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# enabling\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod_with_verbose_kwarg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/git-repos/cfdm/cfdm/read_write/read.py:325\u001b[0m, in \u001b[0;36mread.__new__\u001b[0;34m(cls, datasets, external, extra, verbose, warnings, warn_valid, mask, unpack, domain, netcdf_backend, storage_options, cache, dask_chunks, store_dataset_chunks, store_dataset_shards, cfa, cfa_write, to_memory, squeeze, unsqueeze, dataset_type, recursive, followlinks, cdl_string, extra_read_vars, group_dimension_search, _noncompliance_report, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datasets():\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# Read the dataset\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_read(dataset)\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_read(dataset)\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;66;03m# Add the dataset contents to the output list\u001b[39;00m\n",
      "File \u001b[0;32m~/git-repos/cf-python/cf/read_write/read.py:682\u001b[0m, in \u001b[0;36mread._read\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    677\u001b[0m dataset_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_type\n\u001b[1;32m    679\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;66;03m# Try to read as a netCDF dataset\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 682\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_contents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Successfully read the dataset\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/git-repos/cfdm/cfdm/read_write/read.py:632\u001b[0m, in \u001b[0;36mread._read\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetcdf_read \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    627\u001b[0m         NetCDFRead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimplementation)\u001b[38;5;241m.\u001b[39mread, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnetcdf_kwargs\n\u001b[1;32m    628\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# Try to read the dataset\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetcdf_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DatasetTypeError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/git-repos/cfdm/cfdm/decorators.py:171\u001b[0m, in \u001b[0;36m_manage_log_level_via_verbosity.<locals>.verbose_override_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# After method completes, re-set any changes to log level or\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# enabling\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod_with_verbose_kwarg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/git-repos/cfdm/cfdm/read_write/netcdf/netcdfread.py:2226\u001b[0m, in \u001b[0;36mNetCDFRead.read\u001b[0;34m(self, dataset, extra, default_version, external, extra_read_vars, _scan_only, verbose, mask, unpack, warnings, warn_valid, domain, storage_options, _file_systems, netcdf_backend, cache, dask_chunks, store_dataset_chunks, store_dataset_shards, cfa, cfa_write, to_memory, squeeze, unsqueeze, dataset_type, cdl_string, ignore_unknown_type, group_dimension_search, _noncompliance_report)\u001b[0m\n\u001b[1;32m   2223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ncvar \u001b[38;5;129;01min\u001b[39;00m g[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_not_create_field\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m ncvar \u001b[38;5;129;01min\u001b[39;00m g[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   2224\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 2226\u001b[0m field_or_domain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_field_or_domain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mncvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdomain\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field_or_domain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2230\u001b[0m     all_fields_or_domains[ncvar] \u001b[38;5;241m=\u001b[39m field_or_domain\n",
      "File \u001b[0;32m~/git-repos/cfdm/cfdm/read_write/netcdf/netcdfread.py:4412\u001b[0m, in \u001b[0;36mNetCDFRead._create_field_or_domain\u001b[0;34m(self, field_ncvar, domain, location)\u001b[0m\n\u001b[1;32m   4409\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   4411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coord_ncvar \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m g[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformula_terms\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m-> 4412\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_formula_terms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfield_ncvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoord_ncvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mformula_terms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_ncdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvariable_dimensions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcoord_ncvar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4419\u001b[0m ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   4420\u001b[0m domain_ancillaries \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/git-repos/cfdm/cfdm/conformance/checker.py:1882\u001b[0m, in \u001b[0;36mChecker._check_formula_terms\u001b[0;34m(self, field_ncvar, coord_ncvar, formula_terms, z_ncdim)\u001b[0m\n\u001b[1;32m   1879\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_coordinate_with_bounds:\n\u001b[0;32m-> 1882\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfield_ncvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mncvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFormula terms variable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthat spans the vertical dimension \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhas no bounds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoord_ncvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Report._add_message() got an unexpected keyword argument 'variable'"
     ]
    }
   ],
   "source": [
    "# Read a data file\n",
    "field_list = cf.read('../../ncas_data/ua.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = field_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(field)  # more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.dump()   # maximal (metadata) detail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_field = field * field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(field.data)\n",
    "print(squared_field.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(field.units)\n",
    "print(squared_field.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(field.standard_name)\n",
    "print(squared_field.standard_name)  # this will fail! (explanation to follow!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_field.standard_name = 'square_of_eastward_wind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(field.standard_name)\n",
    "print(squared_field.standard_name)  # this now does not fail, as we have re-assigned a standard name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write out field constructs into netCDF files in any combination we wish. Let's squared field to a netCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.write(squared_field, 'squared_e_wind.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in IPython ! preceeeds a shell command\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ncdump -h squared_e_wind.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here we have read in a field construct from netCDF, created a new field based on the other field's data and metadata, modified the metadata of the new field, and then written in out to a netCDF file.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 2. Basic data analysis, with plotting of results\n",
    "\n",
    "### Plot the data before and after applying statistical collapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cf.read('ncas_data/qbo.nc')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.collapse('maximum', axes='T')  # temporal maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sub = b.subspace(X=30)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfp.con(b_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfp.con(b.subspace(X=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.collapse('mean', axes='X')  # horizontal mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sub = c.subspace(T=cf.dt('1979-01-16 09:00:00'))\n",
    "\n",
    "cfp.con(c_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*That was a demo of some very basic statistical collapsing and sub-spacing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 3. Regridding domains, with plotting of results\n",
    "\n",
    "### Plot the data before and after regridding across spherical and cartesian coordinate systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Regridding across spherical coordinate systems: conservative method as an example\n",
    "\n",
    "Read in two fields, ``f`` and ``g``, where ``f`` is gridded at about twice the resolution of ``g``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a precipitation field and inspect it\n",
    "f = cf.read('ncas_data/precip_2010.nc')[0]\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in another, lower-resolution, precipitation field and inspect it\n",
    "g = cf.read('ncas_data/model_precip_DJF_means_low_res.nc')[0]\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regrid the first field to the grid of the second. We use the `regrids` method of cf-python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1 = f.regrids(g, method='patch')\n",
    "h_2 = f.regrids(g, method='conservative')\n",
    "h_1.equals(h_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect what we have, by plotting the field \"before and after\" (though actually we keep two different fields) the regridding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take some subspaces first:\n",
    "f_sub = f[0]\n",
    "h_1_sub = h_1[0]\n",
    "h_2_sub = h_2[0]\n",
    "\n",
    "\n",
    "# Customising the plots to look nicer\n",
    "cfp.mapset()\n",
    "#cfp.mapset(proj='robin')\n",
    "cfp.cscale('rh_19lev')\n",
    "\n",
    "cfp.gopen(rows=1, columns=2)\n",
    "cfp.gpos(1)\n",
    "cfp.con(f_sub, blockfill=True, lines=False, colorbar_orientation='vertical',\n",
    "        title='Precipitation field before regridding')\n",
    "cfp.gpos(2)\n",
    "cfp.con(h_1_sub, blockfill=True, lines=False, colorbar_orientation='vertical',\n",
    "        title='...and after regridding with patch recovery')\n",
    "cfp.gclose()\n",
    "\n",
    "print(\"Comparing results fom different regridding methods:\")\n",
    "cfp.con(h_2_sub - h_1_sub, lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expect, the regridded field resembles the original in its nature, but is at lower-resolution due to its new grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Regridding across cartesian coordinate systems: time series as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term 'regridding' brings to mind a multi-dimensional grid e.g. over the earth's surface, but a 'grid' is really just a set of points in a multi-dimensional space. In 1D, this is just a series of data points.\n",
    "\n",
    "Cartesian regridding can be used for 1 to 3 dimensions, so we can use it to \"regrid\" such a series, and let's use a time series as an example.\n",
    "\n",
    "Again, start by reading in some (different) precipitation fields, in this case ``i`` and ``j`` which form a pair of time series with different domains/grids i.e. numbers of time data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a precipitation field and inspect it\n",
    "i = cf.read('ncas_data/precip_1D_yearly.nc')[0]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = cf.read('ncas_data/precip_1D_monthly.nc')[0]\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regrid linearly along the time axis 'T' and summarise the resulting field. This time, because we are working with cartesian coordinates, we need to use the `regridc` method on the field acting as the source domain.\n",
    "\n",
    "For diversity, we use a different regridding method. Let's use linear interpolation, by setting `method='linear'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = i.regridc(j, axes='T', method='linear')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the time series before and after regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfp.gopen(rows=1, columns=2)\n",
    "cfp.gpos(1)\n",
    "cfp.lineplot(i, marker='o', color='red',\n",
    "             title='Original time series... before regridding')\n",
    "cfp.gpos(2)\n",
    "cfp.lineplot(k, marker='o', color='blue', title='... and after regridding')\n",
    "cfp.gclose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we've seen that regridding can apply not just to multi-dimensional coordinates but to *data series* (which are *1D \"grids\"*).\n",
    "\n",
    "As you can see, again the nature of the regridding output is preserved, but the granularity has changed, in this case becoming higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 3. Manipulating hierarchical groups\n",
    "\n",
    "### Create & inspect group structure for a netCDF-4 file, then flatten it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*That was a quick demonstration of regridding using both the `regrids` and `regridc` methods for spherical and cartesian coordinate systems respectively, showcasing three different interpolation methods.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to look at groups so let's read in some fields from a netCDF-4 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in IPython ! preceeeds a shell command\n",
    "!ncdump -k ncas_data/data1.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the first field from the `FieldList`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = cf.read('ncas_data/data1.nc')[0]\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is any group structure already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.nc_variable_groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that there is not. But, if we wanted groups, we could create some. A group structure that may be applied when writing to disk can be created from scratch with the netCDF interface, and cf-python provides methods that use this.\n",
    "\n",
    "Here as an example we create a group structure, with `forecast` and `model` as named groups, and write it to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.set_property('comment', 'some general comment')\n",
    "f.nc_set_group_attribute('comment', 'I am part of the model group, a sub-group of forecast')\n",
    "f.nc_set_variable_groups(['forecast', 'model'])\n",
    "\n",
    "f.construct('time').nc_set_variable_groups(['forecast'])\n",
    "\n",
    "cf.write(f, 'grouped.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just check that we wrote out our file by reading it back in again and checking (alternatively, verify with `ncdump`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = cf.read('grouped.nc')[0]\n",
    "print(g)\n",
    "print(f)  # for comparison with original\n",
    "g.equals(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nc_variable_groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are the precise groups we just created, so all is good. We can also verify the groups have been created correctly by inspecting with `ncdump`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in IPython ! preceeeds a shell command\n",
    "!ncdump -h grouped.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nc_group_attributes(values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.construct('latitude').nc_get_variable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default field constructs are written out to a dataset with their groups struct (if any) intact. It is always possible, however, to create a “flat” dataset, i.e. one without any sub-groups, just by setting the `group` keyword argument to `False`, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.write(g, 'flat.nc', group=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = cf.read('flat.nc')[0]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in IPython ! preceeeds a shell command\n",
    "!ncdump -h flat.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.nc_variable_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.nc_group_attributes(values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = cf.read('ncas_data/data1.nc')[0]\n",
    "h.equals(f, verbose='detail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the comment attributes attached to each field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That concludes a quick demo of inspecting and manipulating netCDF-4 hierarchical groups, using cf-python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
